---
alias: testing set
---
#machine_learning  #model_performance 
Set to [Measure model performance](Measure%20model%20performance.md).
If performance of test set << performance of test set ->❌model
20% of data

We must use a separate set 
Test with [training set](training%20set.md) -> memorize data ([Overfitting](Overfitting.md))
Test wih [[Validation set]] -> [[Bias]] (we are evaluating the model the same way we chose the model)
